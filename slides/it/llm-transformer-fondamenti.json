{
  "number": 5,
  "title": "LLM e Transformer: I Fondamenti",
  "description": "Come funzionano, perch√© Google perse, e cosa significa davvero 'ragionare'",
  "steps": [
    {
      "name": "Intro",
      "slides": [
        0
      ]
    },
    {
      "name": "Transformer Explained",
      "slides": [
        1,
        2,
        3,
        4
      ]
    },
    {
      "name": "Storia: Google vs OpenAI",
      "slides": [
        5,
        6,
        7,
        8
      ]
    },
    {
      "name": "Training: Costi e Dati",
      "slides": [
        9,
        10,
        11
      ]
    },
    {
      "name": "Reasoning: LLM vs Umano",
      "slides": [
        12,
        13,
        14,
        15
      ]
    },
    {
      "name": "Discussione",
      "slides": [
        16
      ]
    }
  ],
  "slides": [
    {
      "type": "title",
      "title": "LLM e Transformer",
      "subtitle": "Come Funzionano Davvero",
      "description": "Dalla teoria all'architettura che ha cambiato tutto",
      "ironicClosing": "Google inventa il transformer. OpenAI ci costruisce un impero. Classic."
    },
    {
      "type": "text",
      "title": "Cosa Fa un LLM?",
      "paragraphs": [
        "<strong>Compito base:</strong> Predire la prossima parola",
        "",
        "<strong>Input:</strong> \"Il gatto √® salito sul...\"",
        "<strong>Output:</strong> \"tetto\" (probabilit√† 0.4), \"tavolo\" (0.3), \"divano\" (0.2)...",
        "",
        "<strong>Ma come sceglie?</strong>",
        "‚Ä¢ Contesto: cosa √® venuto prima?",
        "‚Ä¢ Relazioni: \"gatto\" + \"salire\" ‚Üí superfici elevate",
        "‚Ä¢ Pattern appresi: miliardi di esempi visti in training"
      ],
      "ironicClosing": "175 miliardi di parametri per fare autocomplete on steroids. E ha funzionato."
    },
    {
      "type": "text",
      "title": "Il Problema Pre-Transformer",
      "paragraphs": [
        "<strong>RNN (Recurrent Neural Networks):</strong> Leggono parola per parola, sequenzialmente",
        "",
        "<strong>Problema 1 - Memoria corta:</strong>",
        "\"Il gatto che ha mangiato il pesce che era sul tavolo che si trova in cucina √®...\" ‚Üí RNN dimentica \"gatto\"",
        "",
        "<strong>Problema 2 - Lentezza:</strong>",
        "Sequenziale = no parallelizzazione = training lento",
        "",
        "<strong>Problema 3 - Context limitato:</strong>",
        "Difficile catturare relazioni long-range"
      ],
      "ironicClosing": "RNN aveva Alzheimer architetturale. Transformer ha memoria fotografica."
    },
    {
      "type": "text",
      "title": "Transformer: L'Idea Rivoluzionaria",
      "paragraphs": [
        "<strong>2017 - Google Brain:</strong> \"Attention Is All You Need\"",
        "",
        "<strong>L'insight:</strong> Ogni parola guarda <em>tutte</em> le altre parole, in parallelo",
        "",
        "<strong>Esempio:</strong>",
        "\"The animal didn't cross the street because it was too tired\"",
        "",
        "‚Ä¢ \"it\" guarda \"animal\" (alta attention) e \"street\" (bassa attention)",
        "‚Ä¢ Capisce che \"it\" = animal, non street",
        "‚Ä¢ Tutto in parallelo, non sequenziale"
      ],
      "ironicClosing": "Self-attention: ogni parola chiede alle altre 'chi di voi conta davvero?' in parallelo.",
      "citations": [
        {
          "text": "Attention Is All You Need - Google Brain 2017, foundation of all transformers",
          "source": "Vaswani et al. - Transformer Paper",
          "url": "https://arxiv.org/abs/1706.03762"
        }
      ]
    },
    {
      "type": "text",
      "title": "Self-Attention: Come Funziona",
      "paragraphs": [
        "<strong>Per ogni parola, crea 3 vettori:</strong>",
        "",
        "<strong>Query (Q):</strong> \"Cosa sto cercando?\"",
        "<strong>Key (K):</strong> \"Cosa offro?\"",
        "<strong>Value (V):</strong> \"Il mio contenuto effettivo\"",
        "",
        "<strong>Calcolo attention:</strong>",
        "1. Q ¬∑ K = quanto Q e K sono simili (dot product)",
        "2. Softmax = converti in probabilit√†",
        "3. Somma pesata dei Value",
        "",
        "<strong>Risultato:</strong> Ogni parola sa chi √® importante nel contesto"
      ],
      "ironicClosing": "Query, Key, Value: copiato dai database. Il miglior codice √® quello che rubi bene.",
      "citations": [
        {
          "text": "Self-attention uses Query, Key, Value inspired by database retrieval",
          "source": "IBM - Attention Mechanism",
          "url": "https://www.ibm.com/think/topics/attention-mechanism"
        }
      ]
    },
    {
      "type": "text",
      "title": "12 Giugno 2017: Google Inventa il Transformer",
      "paragraphs": [
        "<strong>Paper:</strong> \"Attention Is All You Need\"",
        "",
        "<strong>Team Google Brain:</strong>",
        "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin",
        "",
        "<strong>Breakthrough:</strong> Elimina CNN e RNN, usa solo attention",
        "",
        "<strong>Risultati:</strong>",
        "‚Ä¢ Training 10x pi√π veloce",
        "‚Ä¢ BLEU score migliore su traduzione",
        "‚Ä¢ Scala benissimo (pi√π grande = meglio)"
      ],
      "ironicClosing": "8 ricercatori, 1 paper, fondamenta dell'intera industria AI moderna. Non male come ROI.",
      "citations": [
        {
          "text": "Google Brain team invented transformer architecture June 12, 2017",
          "source": "MIT Technology Review - ChatGPT Origins",
          "url": "https://www.technologyreview.com/2023/02/08/1068068/chatgpt-is-everywhere-heres-where-it-came-from/"
        }
      ]
    },
    {
      "type": "text",
      "title": "2018: OpenAI Colpisce Veloce",
      "paragraphs": [
        "<strong>Giugno 2018 - GPT-1:</strong> OpenAI rilascia primo modello transformer generativo",
        "",
        "<strong>L'insight di OpenAI:</strong>",
        "\"Se scali transformer abbastanza e li traini su dataset enormi, diventano reasoning engines general-purpose\"",
        "",
        "<strong>Strategia:</strong>",
        "‚Ä¢ Pre-train su tutto il testo disponibile",
        "‚Ä¢ Fine-tune per task specifici",
        "‚Ä¢ Scale, scale, scale",
        "",
        "<strong>Google?</strong> Ancora dibattendo rischi reputazionali interni"
      ],
      "ironicClosing": "OpenAI ha letto il paper di Google e ha fatto shipping mentre Google faceva meeting.",
      "citations": [
        {
          "text": "OpenAI released GPT-1 in June 2018, capitalizing on Google's transformer",
          "source": "Wikipedia - GPT",
          "url": "https://en.wikipedia.org/wiki/Generative_pre-trained_transformer"
        }
      ]
    },
    {
      "type": "text",
      "title": "Perch√© Google Perse (Pur Avendo Inventato Tutto)",
      "paragraphs": [
        "<strong>1. Reputation Risk:</strong>",
        "Google terrorizzata: \"E se il modello dice qualcosa di offensivo/biased?\"",
        "",
        "<strong>2. Corporate Inertia:</strong>",
        "Azienda enorme, standard rigidi, product development lento",
        "",
        "<strong>3. Speed:</strong>",
        "Mentre Google dibatteva, OpenAI shippava",
        "",
        "<strong>4. Business Model:</strong>",
        "Google guadagna da ads ‚Üí LLM rischia di cannibalizzare search",
        "",
        "<strong>Lezione:</strong> Inventare ‚â† Vincere. Speed beats perfection."
      ],
      "ironicClosing": "Google inventa. OpenAI shippa. Microsoft paga. Tutti vincono tranne Google.",
      "citations": [
        {
          "text": "Google feared reputation risk and corporate inertia while OpenAI shipped fast",
          "source": "Adjmal - Why Google Missed First Transformer Wave",
          "url": "https://adjmal.com/2025/05/03/the-rise-of-openai-and-why-google-missed-the-first-transformer-wave/"
        }
      ]
    },
    {
      "type": "text",
      "title": "Il Risveglio di Google (Troppo Tardi?)",
      "paragraphs": [
        "<strong>2022 - ChatGPT shock:</strong> Google in panic mode",
        "",
        "<strong>2023 - Bard rilasciato:</strong> Fretta = fail (demo sbagliata, azioni -9%)",
        "",
        "<strong>2024 - Gemini:</strong> Finalmente competitivo",
        "",
        "<strong>2025 - Gemini 2.0:</strong> Alla pari con GPT-4.5/o1",
        "",
        "<strong>Situazione attuale:</strong>",
        "‚Ä¢ Google ha recuperato tecnicamente",
        "‚Ä¢ OpenAI ha brand e momentum",
        "‚Ä¢ Microsoft ha distribution (Office, Windows)",
        "",
        "<strong>Bottom line:</strong> Non √® pi√π solo una corsa tecnica"
      ],
      "ironicClosing": "Recuperare terreno sulla tua stessa invenzione: Google speedrun any%."
    },
    {
      "type": "data",
      "title": "GPT-3: Il Training Che Cambi√≤ Tutto",
      "intro": "<strong>28 Maggio 2020 - OpenAI rilascia GPT-3</strong>",
      "metrics": [
        {
          "value": "175 miliardi",
          "label": "Parametri"
        },
        {
          "value": "499 miliardi",
          "label": "Token usati per training"
        },
        {
          "value": "700 GB",
          "label": "Dataset size (compresso)"
        },
        {
          "value": "$4.6M",
          "label": "Costo training stimato (single run)"
        },
        {
          "value": "355 anni",
          "label": "Tempo su singola GPU (ipotetico)"
        },
        {
          "value": "3.1√ó10¬≤¬≥",
          "label": "FLOPS necessari"
        }
      ],
      "ironicClosing": "$4.6M per autocomplete intelligente. Oggi vale $300 miliardi. Not bad.",
      "citations": [
        {
          "text": "GPT-3: 175B params, 499B tokens, $4.6M cost, 3.1e23 FLOPS",
          "source": "Lambda Labs - GPT-3 Training Cost",
          "url": "https://www.infoq.com/news/2020/06/openai-gpt3-language-model/"
        }
      ]
    },
    {
      "type": "text",
      "title": "Dataset GPT-3: Cosa Ha 'Letto'",
      "paragraphs": [
        "<strong>Composizione del training set (300B token effettivi):</strong>",
        "",
        "<strong>CommonCrawl (60% - 410B token):</strong>",
        "‚Ä¢ Scrape di internet (filtrato per qualit√†)",
        "‚Ä¢ Reddit links con ‚â•3 upvotes come quality signal",
        "",
        "<strong>WebText2 (22%):</strong> Outbound links da Reddit",
        "<strong>Books1 + Books2 (16%):</strong> Libri (non specificati quali)",
        "<strong>Wikipedia (3%):</strong> Tutti gli articoli inglesi",
        "",
        "<strong>Quality > Quantity:</strong> CommonCrawl filtrato pesantemente per similarit√† con corpora di alta qualit√†"
      ],
      "ironicClosing": "Trained on Reddit upvotes. Spiega perch√© GPT-3 a volte suona cos√¨... confident.",
      "citations": [
        {
          "text": "GPT-3 trained on 60% CommonCrawl, 22% WebText2, 16% Books, 3% Wikipedia",
          "source": "DzoLab - GPT-3 Overview",
          "url": "https://dzlab.github.io/ml/2020/07/25/gpt3-overview/"
        }
      ]
    },
    {
      "type": "text",
      "title": "Evoluzione dei Costi: GPT-3 ‚Üí GPT-4",
      "paragraphs": [
        "<strong>GPT-3 (2020):</strong> $4.6M training cost",
        "",
        "<strong>GPT-4 (2023 - stime non ufficiali):</strong>",
        "‚Ä¢ $100M+ training cost stimato",
        "‚Ä¢ 1.7 trillion tokens (vs 300B di GPT-3)",
        "‚Ä¢ 25,000+ A100 GPU per mesi",
        "",
        "<strong>Trend:</strong> Costi crescono esponenzialmente con la scala",
        "",
        "<strong>Implicazione:</strong>",
        "‚Ä¢ Solo big players possono permettersi frontier models",
        "‚Ä¢ Open source modelli mid-size (Llama, Mistral) crescono",
        "‚Ä¢ Inference cost ora > training cost (per molte aziende)"
      ],
      "ironicClosing": "Scaling laws: modelli pi√π grandi = migliori. Budget pi√π grandi = obbligatori."
    },
    {
      "type": "text",
      "title": "LLM Reasoning: o1, o3 e 'Chain of Thought'",
      "paragraphs": [
        "<strong>Settembre 2024 - OpenAI o1:</strong> Il primo \"reasoning model\"",
        "",
        "<strong>Dicembre 2024 - o3:</strong> Ancora meglio",
        "",
        "<strong>Cosa cambia?</strong>",
        "Prima: LLM genera risposta immediatamente",
        "Ora: LLM 'pensa' prima di rispondere (chain of thought)",
        "",
        "<strong>Come funziona:</strong>",
        "‚Ä¢ Reinforcement learning per imparare a ragionare step-by-step",
        "‚Ä¢ 'Private chain of thought' (non vedi il ragionamento)",
        "‚Ä¢ Pu√≤ autocorreggersi, provare approcci diversi",
        "‚Ä¢ Spezza problemi complessi in sottoproblemi"
      ],
      "ironicClosing": "Chain of thought: l'AI mostra il lavoro come in quinta elementare. Ma funziona.",
      "citations": [
        {
          "text": "o1 uses reinforcement learning to learn chain of thought reasoning",
          "source": "OpenAI - Learning to Reason",
          "url": "https://openai.com/index/learning-to-reason-with-llms/"
        }
      ]
    },
    {
      "type": "text",
      "title": "Chain of Thought: Esempio Pratico",
      "paragraphs": [
        "<strong>Problema:</strong> \"Maria ha 3 mele. Compra 5 arance. Quante mele ha?\"",
        "",
        "<strong>GPT-4 (standard):</strong>",
        "‚Üí Risponde \"8\" (sbagliato, somma mele+arance)",
        "",
        "<strong>o1 (reasoning):</strong>",
        "Thought 1: \"Domanda su mele, non frutti totali\"",
        "Thought 2: \"Comprare arance non cambia numero mele\"",
        "Thought 3: \"Maria aveva 3 mele, ha ancora 3 mele\"",
        "‚Üí Risponde \"3\" (corretto)",
        "",
        "<strong>Differenza:</strong> Breaking down, self-correction, focus on relevant info"
      ],
      "ironicClosing": "Reasoning step-by-step: la professoressa di matematica aveva ragione."
    },
    {
      "type": "data",
      "title": "o3 Performance: Vicino all'Umano?",
      "intro": "<strong>Benchmark ARC-AGI (Abstract Reasoning)</strong>",
      "metrics": [
        {
          "value": "87.5%",
          "label": "o3 score su ARC-AGI"
        },
        {
          "value": "85%",
          "label": "Human baseline"
        },
        {
          "value": "5%",
          "label": "GPT-4 score (senza reasoning)"
        }
      ],
      "paragraphs": [
        "<strong>ARC-AGI:</strong> Test di ragionamento astratto visivo (pattern, logica)",
        "<strong>Implicazione:</strong> Su task strutturati (math, logic), o3 compete con umani",
        "<strong>Ma:</strong> Ancora pattern matching, non vera comprensione"
      ],
      "ironicClosing": "87.5% vs 85% umano su test logici. AGI? No. Allarme? Dipende a chi chiedi.",
      "citations": [
        {
          "text": "o3 scores 87.5% on ARC-AGI vs 85% human baseline, 5% GPT-4",
          "source": "Helicone - OpenAI o3 Benchmarks",
          "url": "https://www.helicone.ai/blog/openai-o3"
        }
      ]
    },
    {
      "type": "text",
      "title": "Reasoning LLM vs Reasoning Umano: Le Differenze",
      "paragraphs": [
        "<strong>Cosa hanno in comune:</strong>",
        "‚Ä¢ Step-by-step decomposition",
        "‚Ä¢ Self-correction quando approach non funziona",
        "‚Ä¢ Focus su informazioni rilevanti",
        "",
        "<strong>Differenze critiche:</strong>",
        "",
        "<strong>1. Mechanism:</strong>",
        "‚Ä¢ Umano: comprensione semantica, modello mentale del mondo",
        "‚Ä¢ LLM: pattern matching su scala, nessuna vera comprensione",
        "",
        "<strong>2. Generalizzazione:</strong>",
        "‚Ä¢ Umano: trasferisce conoscenza a domini nuovi",
        "‚Ä¢ LLM: eccelle in domini strutturati visti in training, fatica su novel contexts"
      ],
      "ironicClosing": "Simulare reasoning perfettamente = reasoning? Filosofi dibattono. Venture capitalist investono."
    },
    {
      "type": "text",
      "title": "Domande per Discussione üí¨",
      "paragraphs": [
        "<strong>1. Google vs OpenAI:</strong>",
        "Google ha sbagliato ad essere cauta? O OpenAI √® stata irresponsabile nel muoversi veloce?",
        "",
        "<strong>2. Costi Training:</strong>",
        "$100M+ per GPT-4. Questo concentra potere nelle mani di pochi big player? √à un problema?",
        "",
        "<strong>3. Reasoning:</strong>",
        "Se o3 passa test umani ma non 'capisce' davvero, conta? Quando dobbiamo fidarci del reasoning AI?",
        "",
        "<strong>4. Dataset:</strong>",
        "GPT ha 'letto' internet senza consenso. √à ok? Come gestiamo copyright e privacy?",
        "",
        "<strong>5. Future:</strong>",
        "Quando (se mai) LLM reasoning diventer√† indistinguibile da quello umano?"
      ],
      "ironicClosing": "Le domande etiche non si risolvono con pi√π GPU. Peccato."
    }
  ],
  "lastTranslated": null,
  "sourceLanguage": "it"
}